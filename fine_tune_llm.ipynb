{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate sacrebleu","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-27T20:22:41.777210Z","iopub.execute_input":"2023-11-27T20:22:41.777768Z","iopub.status.idle":"2023-11-27T20:22:56.513279Z","shell.execute_reply.started":"2023-11-27T20:22:41.777737Z","shell.execute_reply":"2023-11-27T20:22:56.512092Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting sacrebleu\n  Obtaining dependency information for sacrebleu from https://files.pythonhosted.org/packages/df/c0/ff53cb76c1b050ad25d056877ba6d3f6fa964134370c4ccf57ad933d6f72/sacrebleu-2.3.2-py3-none-any.whl.metadata\n  Downloading sacrebleu-2.3.2-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nCollecting portalocker (from sacrebleu)\n  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.8.8)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.3.2-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker, sacrebleu, evaluate\nSuccessfully installed evaluate-0.4.1 portalocker-2.8.2 sacrebleu-2.3.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import (AutoTokenizer, DataCollatorForSeq2Seq,\nAutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer)\nfrom datasets import load_dataset\nfrom huggingface_hub import notebook_login\n\nimport numpy as np\nimport evaluate","metadata":{"execution":{"iopub.status.busy":"2023-11-27T20:23:33.880090Z","iopub.execute_input":"2023-11-27T20:23:33.880466Z","iopub.status.idle":"2023-11-27T20:23:54.617771Z","shell.execute_reply.started":"2023-11-27T20:23:33.880431Z","shell.execute_reply":"2023-11-27T20:23:54.616862Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"notebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T20:23:59.265748Z","iopub.execute_input":"2023-11-27T20:23:59.266473Z","iopub.status.idle":"2023-11-27T20:23:59.290375Z","shell.execute_reply.started":"2023-11-27T20:23:59.266435Z","shell.execute_reply":"2023-11-27T20:23:59.289063Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9587ee2962a340d6aa0884bc957f1000"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [PREFIX + example[SRC_LANG] for example in examples[\"translation\"]]\n    targets = [example[TGT_LANG] for example in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs\n                             , text_target = targets\n                             , max_length = MAX_LENGTH\n                             , padding = \"max_length\"\n                             , truncation = True)\n    return model_inputs\n\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    #print(preds)\n    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n    #preds = [tid for tid in preds.flatten() if tid >= 0 and tid < tokenizer.vocab_size]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-11-27T21:15:55.922751Z","iopub.execute_input":"2023-11-27T21:15:55.923683Z","iopub.status.idle":"2023-11-27T21:15:55.934792Z","shell.execute_reply.started":"2023-11-27T21:15:55.923642Z","shell.execute_reply":"2023-11-27T21:15:55.933642Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"MODEL_CHECKPOINT = \"t5-base\"\nSRC_LANG = \"en\"\nTGT_LANG = \"de\"\nPREFIX = \"translate English to German: \"\nMAX_LENGTH = 128","metadata":{"execution":{"iopub.status.busy":"2023-11-27T20:24:39.698934Z","iopub.execute_input":"2023-11-27T20:24:39.699829Z","iopub.status.idle":"2023-11-27T20:24:39.703974Z","shell.execute_reply.started":"2023-11-27T20:24:39.699792Z","shell.execute_reply":"2023-11-27T20:24:39.703074Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"raw_data = load_dataset(\"opus_books\", lang1=TGT_LANG, lang2=SRC_LANG)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2023-11-27T20:24:45.943439Z","iopub.execute_input":"2023-11-27T20:24:45.943799Z","iopub.status.idle":"2023-11-27T20:24:52.827652Z","shell.execute_reply.started":"2023-11-27T20:24:45.943767Z","shell.execute_reply":"2023-11-27T20:24:52.826586Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fc0b74b8a2f4ee8b62d9afe5235be4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/7.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b35cf76e7ba841c797aec6924bea51ec"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset opus_books/de-en (download: 4.89 MiB, generated: 13.10 MiB, post-processed: Unknown size, total: 17.99 MiB) to /root/.cache/huggingface/datasets/opus_books/de-en-lang1=de,lang2=en/0.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a01ba7469d4c05bbe0909d2bb9adeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51467 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset opus_books downloaded and prepared to /root/.cache/huggingface/datasets/opus_books/de-en-lang1=de,lang2=en/0.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bffcd624a63f44cab2483ec782775b77"}},"metadata":{}}]},{"cell_type":"code","source":"split_data = raw_data[\"train\"].train_test_split(train_size=0.9, seed=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T20:24:54.217774Z","iopub.execute_input":"2023-11-27T20:24:54.218463Z","iopub.status.idle":"2023-11-27T20:24:54.250684Z","shell.execute_reply.started":"2023-11-27T20:24:54.218426Z","shell.execute_reply":"2023-11-27T20:24:54.249785Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T20:24:56.726837Z","iopub.execute_input":"2023-11-27T20:24:56.727755Z","iopub.status.idle":"2023-11-27T20:24:57.904319Z","shell.execute_reply.started":"2023-11-27T20:24:56.727712Z","shell.execute_reply":"2023-11-27T20:24:57.903273Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"562b940d29f942a097f003bc63a152f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"773322da5a034ef580612d7fe87705e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36534121d5804f5fa0026d5bd3baff03"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-27T20:25:02.835129Z","iopub.execute_input":"2023-11-27T20:25:02.835817Z","iopub.status.idle":"2023-11-27T20:25:10.215575Z","shell.execute_reply.started":"2023-11-27T20:25:02.835784Z","shell.execute_reply":"2023-11-27T20:25:10.214372Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78faeeddb1e3434599aefdece315458e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b69649de90749c58357a436b96aa64c"}},"metadata":{}}]},{"cell_type":"code","source":"token_data = split_data.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T21:16:00.542745Z","iopub.execute_input":"2023-11-27T21:16:00.543173Z","iopub.status.idle":"2023-11-27T21:16:00.557327Z","shell.execute_reply.started":"2023-11-27T21:16:00.543138Z","shell.execute_reply":"2023-11-27T21:16:00.556532Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer\n                                       , model = MODEL_CHECKPOINT)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T20:35:22.097373Z","iopub.execute_input":"2023-11-27T20:35:22.098285Z","iopub.status.idle":"2023-11-27T20:35:22.102655Z","shell.execute_reply.started":"2023-11-27T20:35:22.098249Z","shell.execute_reply":"2023-11-27T20:35:22.101630Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2023-11-27T20:26:11.287649Z","iopub.execute_input":"2023-11-27T20:26:11.288067Z","iopub.status.idle":"2023-11-27T20:26:11.954147Z","shell.execute_reply.started":"2023-11-27T20:26:11.288027Z","shell.execute_reply":"2023-11-27T20:26:11.953075Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53956d62b47f4743863dae612819fcb8"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir = \"t5-base_fine-tuned_opus-books_en-de\",\n    evaluation_strategy = \"epoch\",\n    learning_rate = 5e-5,\n    per_device_train_batch_size = 16,\n    per_device_eval_batch_size = 16,\n    weight_decay = 0.01,\n    save_total_limit = 3,\n    num_train_epochs = 3,\n    predict_with_generate = True,\n    fp16 = True,\n    push_to_hub = True,\n    report_to=\"none\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = token_data[\"train\"],\n    eval_dataset = token_data[\"test\"],\n    tokenizer = tokenizer,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T21:28:00.564084Z","iopub.execute_input":"2023-11-27T21:28:00.564459Z","iopub.status.idle":"2023-11-27T21:28:00.744540Z","shell.execute_reply.started":"2023-11-27T21:28:00.564433Z","shell.execute_reply":"2023-11-27T21:28:00.743620Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate(max_length=MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T21:28:04.337085Z","iopub.execute_input":"2023-11-27T21:28:04.337800Z","iopub.status.idle":"2023-11-27T21:34:44.531891Z","shell.execute_reply.started":"2023-11-27T21:28:04.337768Z","shell.execute_reply":"2023-11-27T21:34:44.530948Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='322' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [161/161 42:17]\n    </div>\n    "},"metadata":{}},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 13.984762191772461,\n 'eval_bleu': 11.8599,\n 'eval_gen_len': 36.3622,\n 'eval_runtime': 400.1844,\n 'eval_samples_per_second': 12.862,\n 'eval_steps_per_second': 0.402}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T21:37:45.959366Z","iopub.execute_input":"2023-11-27T21:37:45.959793Z","iopub.status.idle":"2023-11-27T23:16:29.575956Z","shell.execute_reply.started":"2023-11-27T21:37:45.959760Z","shell.execute_reply":"2023-11-27T23:16:29.574971Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4344' max='4344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4344/4344 1:38:41, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.646300</td>\n      <td>0.550666</td>\n      <td>5.306300</td>\n      <td>17.027000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.598000</td>\n      <td>0.536998</td>\n      <td>5.470800</td>\n      <td>17.026400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.581800</td>\n      <td>0.534076</td>\n      <td>5.559700</td>\n      <td>17.026200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4344, training_loss=0.6497323297883485, metrics={'train_runtime': 5923.0305, 'train_samples_per_second': 23.461, 'train_steps_per_second': 0.733, 'total_flos': 2.11551971180544e+16, 'train_loss': 0.6497323297883485, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate(max_length=MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:20:03.427281Z","iopub.execute_input":"2023-11-27T23:20:03.429138Z","iopub.status.idle":"2023-11-27T23:27:30.161293Z","shell.execute_reply.started":"2023-11-27T23:20:03.429091Z","shell.execute_reply":"2023-11-27T23:27:30.160286Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [161/161 07:21]\n    </div>\n    "},"metadata":{}},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.5340757369995117,\n 'eval_bleu': 17.263,\n 'eval_gen_len': 38.3748,\n 'eval_runtime': 446.7223,\n 'eval_samples_per_second': 11.522,\n 'eval_steps_per_second': 0.36,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(tags=\"translation\", commit_message=\"Training complete\")","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:31:46.035353Z","iopub.execute_input":"2023-11-27T23:31:46.036262Z","iopub.status.idle":"2023-11-27T23:32:24.264554Z","shell.execute_reply.started":"2023-11-27T23:31:46.036217Z","shell.execute_reply":"2023-11-27T23:32:24.263492Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1aa5af29f784168abf7391b8f98d896"}},"metadata":{}},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/jaymanvirk/t5-base_fine-tuned_opus-books_en-de/tree/main/'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}