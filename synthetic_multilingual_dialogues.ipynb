{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4298,"sourceType":"modelInstanceVersion","modelInstanceId":3093},{"sourceId":5111,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3899},{"sourceType":"modelInstanceVersion","sourceId":4307,"isSourceIdPinned":true}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport transformers\nfrom datasets import load_dataset\nimport torch\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-11-26T20:42:09.134735Z","iopub.execute_input":"2023-11-26T20:42:09.135924Z","iopub.status.idle":"2023-11-26T20:42:18.723985Z","shell.execute_reply.started":"2023-11-26T20:42:09.135891Z","shell.execute_reply":"2023-11-26T20:42:18.723120Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def get_sequences(prompt, tokenizer, llm_pipeline):\n    sequences = llm_pipeline(\n        prompt\n        , num_return_sequences=1\n        , eos_token_id = tokenizer.eos_token_id\n    )\n    return sequences\n\ndef get_pipeline(model):\n    pipeline = transformers.pipeline(\n        \"text-generation\"\n        , model = model\n        , torch_dtype = torch.float16\n        , device_map = \"auto\"\n    )\n    return pipeline\n\ndef get_json_format(text):\n    dialogues = []\n    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n\n    situation = []\n\n    for line in lines:\n        if not line.startswith(\"Situation\"):\n            situation.append(line.strip())\n\n    return situation","metadata":{"execution":{"iopub.status.busy":"2023-11-26T21:40:56.448412Z","iopub.execute_input":"2023-11-26T21:40:56.449281Z","iopub.status.idle":"2023-11-26T21:40:56.456454Z","shell.execute_reply.started":"2023-11-26T21:40:56.449245Z","shell.execute_reply":"2023-11-26T21:40:56.455579Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# mistral_path = \"/kaggle/input/mistral/pytorch/7b-v0.1-hf/1\"\n# mistral_tokenizer = AutoTokenizer.from_pretrained(mistral_path)\n# mistral_pipeline = get_pipeline(mistral_path)\n\nllama_path = \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\"\nllama_tokenizer = AutoTokenizer.from_pretrained(llama_path)\nllama_pipeline = get_pipeline(llama_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T21:11:53.094319Z","iopub.execute_input":"2023-11-26T21:11:53.095234Z","iopub.status.idle":"2023-11-26T21:11:59.249334Z","shell.execute_reply.started":"2023-11-26T21:11:53.095197Z","shell.execute_reply":"2023-11-26T21:11:59.248470Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d089f5982acd48008f045d5594e1a173"}},"metadata":{}}]},{"cell_type":"code","source":"prompt = f'''\n            Describe five situations between two friends on different occasions.\n            The topic is {topics[0]}.\n            '''\nseq = get_sequences(prompt, llama_tokenizer, llama_pipeline)\nseq = seq[0][\"generated_text\"].replace(prompt, \"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sits = get_json_format(seq)[:5]","metadata":{"execution":{"iopub.status.busy":"2023-11-26T21:57:31.154215Z","iopub.execute_input":"2023-11-26T21:57:31.154601Z","iopub.status.idle":"2023-11-26T21:57:31.159134Z","shell.execute_reply.started":"2023-11-26T21:57:31.154570Z","shell.execute_reply":"2023-11-26T21:57:31.158137Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"prompt = f'''\n        Create a dialogue between 2 friends, given this situation: {sits[0]}\n'''\nseq = get_sequences(prompt, llama_tokenizer, llama_pipeline)\nseq = seq[0][\"generated_text\"].replace(prompt, \"\")\nseq","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}